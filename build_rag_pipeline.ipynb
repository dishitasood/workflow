{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLyi+PXfvxq04Ms3l8PhyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dishitasood/workflow/blob/master/build_rag_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1: Loading PDF"
      ],
      "metadata": {
        "id": "V_JehrPqp01G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary libraries\n",
        "!pip install -q llama-index llama-index-llms-gemini pymupdf\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install nest_asyncio\n",
        "!pip install --upgrade transformers\n",
        "!pip install -U sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTh5do_ipxey",
        "outputId": "5af94845-6e05-41d7-8a68-be446ec4b300"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "import nest_asyncio"
      ],
      "metadata": {
        "id": "U2WUn4olqgIg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qIzErhYPpQnF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "GOOGLE_API_KEY = \"AIzaSyC8DoAne5KteQkeWFOMUGFvmFZTvwbyah4\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "pyPizZp6qac3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p sample_docs"
      ],
      "metadata": {
        "id": "SK7C1ym7qj4A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def upload_pdf():\n",
        "    \"\"\"Upload a PDF file and return its path.\"\"\"\n",
        "    print(\"Please select a PDF file to upload:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.pdf'):\n",
        "            # Save to the sample_docs directory\n",
        "            pdf_path = os.path.join(\"sample_docs\", filename)\n",
        "\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(\"sample_docs\", exist_ok=True)\n",
        "\n",
        "            # Save the file\n",
        "            with open(pdf_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "\n",
        "            print(f\"PDF saved to {pdf_path}\")\n",
        "            return pdf_path\n",
        "        else:\n",
        "            print(f\"File {filename} is not a PDF. Please upload a PDF file.\")\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "lDTv0NoAqu-v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = upload_pdf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "bTxxhVZoq_V5",
        "outputId": "80b77128-4912-481b-fd74-d3c497c24a3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a PDF file to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5945378-3bcd-485d-b492-7c3558f8e3b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5945378-3bcd-485d-b492-7c3558f8e3b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LenderFeesWorksheetNew.pdf to LenderFeesWorksheetNew.pdf\n",
            "PDF saved to sample_docs/LenderFeesWorksheetNew.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "\n",
        "  doc = fitz.open(pdf_path)\n",
        "\n",
        "  # extract texts from all pages\n",
        "  text = \"\\n\".join([page.get_text() for page in doc])\n",
        "\n",
        "  print(\"PDF: \", {pdf_path})\n",
        "  print(\"Number of pages: \", len(doc))\n",
        "  print(f\"Extracted {len(text.split())} from the pdf\")\n",
        "\n",
        "  doc.close()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "Qofv4Y5yrGcy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if pdf_path:\n",
        "  text = extract_text_from_pdf(pdf_path)\n",
        "  print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBBYAR_6sBJU",
        "outputId": "29f1a386-046b-4ac3-a46c-a08a19dd61ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF:  {'sample_docs/LenderFeesWorksheetNew.pdf'}\n",
            "Number of pages:  1\n",
            "Extracted 404 from the pdf\n",
            "Your actual rate, payment, and cost could be higher. Get an official Loan Estimate before choosing a loan.\n",
            "Fee Details and Summary\n",
            "Applicants:\n",
            "Application No:\n",
            "Date Prepared:\n",
            "Loan Program:\n",
            "Prepared By:\n",
            "THIS IS NOT A GOOD FAITH ESTIMATE (GFE). This \"Fees Worksheet\" is provided for informational purposes ONLY, to assist\n",
            "you in determining an estimate of cash that may be required to close and an estimate of your proposed monthly mortgage \n",
            "payment. Actual charges may be more or less, and your transac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integrating PyMuPDF with LlamaIndex"
      ],
      "metadata": {
        "id": "5lvyxYUksrPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from typing import List\n",
        "\n",
        "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
        "\n",
        "  # open the pdf\n",
        "  doc = fitz.open(pdf_path)\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for i, page in enumerate(doc):\n",
        "    text = page.get_text()\n",
        "\n",
        "    if not text.strip():\n",
        "      continue\n",
        "\n",
        "    documents.append(\n",
        "        Document(\n",
        "            text=text,\n",
        "            metadata={\n",
        "                \"file_name\": os.path.basename(pdf_path),\n",
        "                \"page_number\": i + 1,\n",
        "                \"total_pages\": len(doc)\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "\n",
        "  doc.close()\n",
        "\n",
        "  print(f\"Processed {pdf_path}:\")\n",
        "  print(f\"Extracted {len(documents)} pages with content\")\n",
        "\n",
        "  return documents\n",
        "\n"
      ],
      "metadata": {
        "id": "EGP8wJFusnJi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage\n",
        "pdf_docs = load_pdf_with_pymupdf(pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_nd9MkxuR6U",
        "outputId": "0e7f92d9-66de-49d8-be72-896975a19950"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed sample_docs/LenderFeesWorksheetNew.pdf:\n",
            "Extracted 1 pages with content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata # Import userdata\n",
        "GOOGLE_API_KEY = userdata.get('gemini_key')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "GXUQddGwq_TJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2: Idexing and Processing PDFs"
      ],
      "metadata": {
        "id": "PBDyhqKahV8j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cda137f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9476cc3c-b356-45d2-c0b0-8feb180807d5"
      },
      "source": [
        "!pip install -q llama-index-llms-google-genai"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function Client.__del__ at 0x7cd0c1ea23e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/client.py\", line 400, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/client.py\", line 386, in close\n",
            "    self._api_client.close()\n",
            "    ^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'Client' object has no attribute '_api_client'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53c7e60c"
      },
      "source": [
        "To add your API key to Colab secrets:\n",
        "\n",
        "1. Click on the \"ðŸ”‘\" icon in the left sidebar of your Colab notebook.\n",
        "2. Click on \"Add new secret\".\n",
        "3. In the \"Name\" field, enter a name for your secret (e.g., `GOOGLE_API_KEY`).\n",
        "4. In the \"Value\" field, paste your API key.\n",
        "5. Make sure the \"Notebook access\" toggle is turned on for the current notebook.\n",
        "6. Click \"Done\".\n",
        "\n",
        "Now you can access your API key in your code using `userdata.get('YOUR_SECRET_NAME')`, replacing `YOUR_SECRET_NAME` with the name you gave your secret."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding # Import HuggingFaceEmbedding\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "\n",
        "\n",
        "# #initalize gemini llm\n",
        "llm = GoogleGenAI(\n",
        "    model=\"gemini-2.5-flash\"\n",
        ")\n",
        "Settings.llm = llm\n",
        "\n",
        "#initialize embedding model, sentence transformer\n",
        "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embed_model = HuggingFaceEmbedding(model_name=embed_model_name) # Wrap SentenceTransformer model\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "def process_index_pdf(pdf_path):\n",
        "\n",
        "  #load documents\n",
        "  documents = load_pdf_with_pymupdf(pdf_path)\n",
        "\n",
        "  #create vector index\n",
        "  index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "  print(f\"Indexed {len(documents)} document chunks\")\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gG6sy7chbnX",
        "outputId": "68f136cd-6db3-4ac3-a6e5-9443c7588e71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if pdf_path:\n",
        "  index = process_index_pdf(pdf_path)\n",
        "else:\n",
        "  print(\"No PDF file uploaded. Please upload a PDF file using the previous cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_HFzx43iu-H",
        "outputId": "e6726fe0-e009-4f68-9023-172961a7c04f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed sample_docs/LenderFeesWorksheetNew.pdf:\n",
            "Extracted 1 pages with content\n",
            "Indexed 1 document chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3: Implementing Query Expansion and Rewriting"
      ],
      "metadata": {
        "id": "INXtFEKGrcId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# Initialize Gemini LLM\n",
        "llm = GoogleGenAI(\n",
        "    model=\"gemini-2.5-flash\"\n",
        ")\n",
        "Settings.llm = llm\n",
        "\n",
        "#simple query expansion function using Gemini\n",
        "def expand_query(query: str, num_expansions: int = 3 ) -> list:\n",
        "  prompt = f\"\"\"\n",
        "    I need to search a legal contract with this query: \"{query}\"\n",
        "\n",
        "    Please help me expand this query by generating {num_expansions} alternative versions that:\n",
        "    1. Use different but related terminology\n",
        "    2. Include relevant legal terms that might appear in a contract\n",
        "    3. Cover similar concepts but phrased differently\n",
        "\n",
        "    Format your response as a list of alternative queries only, with no additional text.\n",
        "    \"\"\"\n",
        "\n",
        "  response = llm.complete(prompt)\n",
        "\n",
        "  #extract the expanded queries\n",
        "  expanded_queries = [line.strip() for line in response.text.split('\\n') if line.strip()]\n",
        "\n",
        "  #add the original query if needed\n",
        "  if query not in expanded_queries:\n",
        "    expanded_queries = [query] + expanded_queries\n",
        "\n",
        "  return expanded_queries"
      ],
      "metadata": {
        "id": "lvxMx9xEnF7O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Usage\n",
        "expanded = expand_query(\"What are the penalties for late payments?\")\n",
        "for i, q in enumerate(expanded):\n",
        "  print(f\"{i+1}.{q}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLOYPegy4t8b",
        "outputId": "edfec7de-bae4-42ea-f15f-3677ec947406"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.What are the penalties for late payments?\n",
            "2.*   What are the remedies or consequences for payment default?\n",
            "3.*   What are the charges, including default interest or administrative fees, for overdue amounts?\n",
            "4.*   What are the liabilities or liquidated damages for a breach of payment terms?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating a Query Expansion Engine"
      ],
      "metadata": {
        "id": "S3xHfcA06Ez5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import QueryFusionRetriever\n",
        "\n",
        "\n",
        "def create_query_expansion_engine(index):\n",
        "  \"\"\"Create a query engine that uses query expansion.\"\"\"\n",
        "  # first create multiple retrivers\n",
        "  base_retriever = index.as_retriever(similarity_top_k=2)\n",
        "\n",
        "  #create a qeury fusion retriever\n",
        "  fusion_retriever = QueryFusionRetriever(\n",
        "      retrievers = [base_retriever],\n",
        "      llm=llm,\n",
        "      similarity_top_k=2,\n",
        "      num_queries=3,\n",
        "      mode=\"reciprocal_rerank\"\n",
        "      )\n",
        "\n",
        "  #create query engine with query fusion rteriever\n",
        "  query_engine = RetrieverQueryEngine.from_args(\n",
        "      retriever=fusion_retriever,\n",
        "      llm=llm,\n",
        "      verbose=True\n",
        "  )\n",
        "\n",
        "  return query_engine"
      ],
      "metadata": {
        "id": "sjEp2DrX6GOO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example usage\n",
        "expanded_query_engine = create_query_expansion_engine(index)\n",
        "response = expanded_query_engine.query(\"What is lender fees\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_UBga5J9ak0",
        "outputId": "d3d66052-5d98-4eda-aa53-364714251a68"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lender fees include an Underwriting Fee of $550.00, a Wire Transfer Fee of $75.00, and an Administration Fee of $445.00. Other charges paid to the lender are an Appraisal Fee of $525.00, a Credit Report Fee of $25.00, a Tax Service Fee of $80.00, a Flood Certification Fee of $20.00, and Daily Interest Charges totaling $1,121.53.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-retrievers-bm25"
      ],
      "metadata": {
        "id": "BRvZ9Bc7-1Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sz-qPcvA-4MD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}